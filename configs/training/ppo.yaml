# PPO 训练配置
algorithm: ppo

# 训练参数
training:
  total_steps: 1000000
  batch_size: 256
  learning_rate: 0.0001
  gamma: 0.99
  gae_lambda: 0.95

  # PPO 特定参数
  clip_range: 0.2
  epochs: 4
  n_envs: 8
  n_steps: 128

  # 损失系数
  value_loss_coef: 0.5
  entropy_coef: 0.01
  max_grad_norm: 0.5

# 模型配置
model:
  backbone: resnet
  hidden_dim: 512
  num_layers: 4
  use_se: true

# 保存配置
checkpoint:
  save_dir: checkpoints/ppo
  save_freq: 10000
  log_dir: logs/ppo
